{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from cjm_psl_utils.core import download_file, file_extract\n",
    "from cjm_torchvision_tfms.core import ResizeMax, PadSquare, CustomRandomIoUCrop\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(42)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "import cv2 as cv\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from torch.autograd import Variable\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Import torchvision dependencies\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "from torchvision.tv_tensors import BoundingBoxes\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torchvision.transforms.v2  as transforms\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import CardDlayingDataset, final_transforms, custom_collate\n",
    "from model import CenterNet\n",
    "from loss import focal_loss, get_predictions_from_head\n",
    "from inferance import gather_feature, topKscoresPerBatch, pool_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_feature(fmap, index, mask=None, use_transform=False):\n",
    "    if use_transform:\n",
    "        # change a (N, C, H, W) tenor to (N, HxW, C) shape\n",
    "        batch, channel = fmap.shape[:2]\n",
    "        fmap = fmap.view(batch, channel, -1).permute((0, 2, 1)).contiguous()\n",
    "    print('----------> ', fmap.shape)\n",
    "    dim = fmap.size(-1)\n",
    "    index = index.unsqueeze(len(index.shape)).expand(*index.shape, dim)\n",
    "    print('----------> ', index)\n",
    "    fmap = fmap.gather(dim=1, index=index)\n",
    "\n",
    "\n",
    "    if mask is not None:\n",
    "        # this part is not called in Res18 dcn COCO\n",
    "        mask = mask.unsqueeze(2).expand_as(fmap)\n",
    "        fmap = fmap[mask]\n",
    "        fmap = fmap.reshape(-1, dim)\n",
    "    return fmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5]) torch.Size([2, 2, 64, 64])\n",
      "---------->  torch.Size([2, 4096, 2])\n",
      "---------->  tensor([[[27, 27],\n",
      "         [ 3,  3],\n",
      "         [ 6,  6],\n",
      "         [51, 51],\n",
      "         [63, 63]],\n",
      "\n",
      "        [[14, 14],\n",
      "         [15, 15],\n",
      "         [28, 28],\n",
      "         [30, 30],\n",
      "         [ 6,  6]]])\n",
      "torch.Size([2, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "index = np.random.randint(0, 64, (2, 5))\n",
    "index = torch.tensor(index)\n",
    "\n",
    "size = torch.rand(2, 2, 64, 64)\n",
    "\n",
    "print(index.shape, size.shape)\n",
    "\n",
    "fmap = gather_feature(size, index, use_transform=True)\n",
    "\n",
    "print(fmap.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000],\n",
      "        [0.5000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "# Bounding boxes in format [x1, y1, x2, y2]\n",
    "boxes1 = torch.tensor([[0, 0, 1, 1], [0, 0, 2, 1]])\n",
    "boxes2 = torch.tensor([[0, 0, 1, 1]])\n",
    "\n",
    "iou = box_iou(boxes1, boxes2)\n",
    "print(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial tensor: tensor([1, 7, 5, 4])\n",
      "sorted tensor: tensor([1, 4, 5, 7])\n",
      "indices: tensor([0, 3, 2, 1])\n",
      "reorganised bbox:\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([4, 4, 4, 4])\n",
      "tensor([3, 3, 3, 3])\n",
      "tensor([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "test = torch.tensor([1, 7, 5, 4])\n",
    "\n",
    "bbox = torch.tensor([[1, 1, 1, 1],\n",
    "                     [2, 2, 2, 2],\n",
    "                     [3, 3, 3, 3],\n",
    "                     [4, 4, 4, 4]])\n",
    "\n",
    "print('initial tensor:', test)\n",
    "\n",
    "test, indices = test.sort()\n",
    "\n",
    "print('sorted tensor:', test)\n",
    "print('indices:', indices)\n",
    "\n",
    "bbox = bbox[indices, ::] \n",
    "\n",
    "print('reorganised bbox:')\n",
    "for zz in bbox:\n",
    "    print(zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5560]])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.ops import box_iou\n",
    "\n",
    "boxes1 = torch.tensor([[152.1973, 122.4850, 165.6881, 164.4115]])\n",
    "boxes2 = torch.tensor([[151.6000, 123.6000, 167.6000, 149.6000]])\n",
    "\n",
    "iou = box_iou(boxes1, boxes2)\n",
    "print(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
