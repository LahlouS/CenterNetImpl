{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(nn.Module):\n",
    "    def __init__(self): # TODO later add config parameter to choose differente architectures\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        # we keep intermediates outputs for the FPN to do his job\n",
    "        x1 = self.model.layer1(x)\n",
    "        x2 = self.model.layer2(x1)\n",
    "        x3 = self.model.layer3(x2)\n",
    "        x4 = self.model.layer4(x3)\n",
    "\n",
    "        return x1, x2, x3, x4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can see that the output shape is (1000, 1) due to the last fully connected layer. we dont want that as we just want to use the extracting feature power of resnet so lets modify our forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "x1.shape: torch.Size([1, 256, 64, 64]) x2.shape: torch.Size([1, 512, 32, 32]) x3.shape: torch.Size([1, 1024, 16, 16]) x4.shape: torch.Size([1, 2048, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "m = BackBone()\n",
    "\n",
    "# for name, module in m.named_modules():\n",
    "#     print(f'|{name}|')\n",
    "    # print(module)\n",
    "# input_size = (3, 256, 256)\n",
    "# summary(m, input_size)\n",
    "t = torch.rand(1, 3, 256, 256)\n",
    "print(t.shape)\n",
    "with torch.no_grad():\n",
    "    x1, x2, x3, x4 = m(t)\n",
    "\n",
    "print('x1.shape:', x1.shape, 'x2.shape:', x2.shape, 'x3.shape:', x3.shape, 'x4.shape:', x4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Good, we can see our output shape is now 8x8 x2048 channels, this is what we want as the furthers models are convolutional too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2048, 512), (1024, 512), (512, 512), (256, 512)]\n"
     ]
    }
   ],
   "source": [
    "# tests\n",
    "\n",
    "lst = [(2048 // (2 ** c), 512) for c in range(4)]\n",
    "\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm = nn.BatchNorm2d\n",
    "\n",
    "\n",
    "class Conv1x1(nn.Module):\n",
    "    def __init__(self, num_in, num_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(num_in, num_out, kernel_size=1, bias=False)\n",
    "        self.norm = Norm(num_out)\n",
    "        self.active = nn.ReLU(True)\n",
    "        self.block = nn.Sequential(self.conv, self.norm, self.active)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class Conv3x3(nn.Module):\n",
    "    def __init__(self, num_in, num_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(num_in, num_out, kernel_size=3, padding=1,\n",
    "                              bias=False)\n",
    "        self.norm = Norm(num_out)\n",
    "        self.active = nn.ReLU(True)\n",
    "        self.block = nn.Sequential(self.conv, self.norm, self.active)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class FPN(nn.Module):\n",
    "    def __init__(self, inplanes = 2048, outplanes = 256):\n",
    "        super(FPN, self).__init__()\n",
    "\n",
    "        self.laterals = nn.Sequential(*[Conv1x1(inplanes // (2 ** c), outplanes) for c in range(4)])\n",
    "        self.smooths = nn.Sequential(*[Conv3x3(outplanes * c, outplanes * c) for c in range(1, 5)])\n",
    "        self.pooling = nn.MaxPool2d(2)\n",
    "\n",
    "        self.out_channels = outplanes * 4 # because our top-down pathway is composed of 4 layers\n",
    "\n",
    "    def forward(self, features):\n",
    "        laterals = [lateral(features[f]) for f, lateral in enumerate(self.laterals)]\n",
    "\n",
    "        map4 = laterals[0]\n",
    "\n",
    "        map3 = laterals[1] + nn.functional.interpolate(map4, scale_factor=2, mode=\"nearest\")\n",
    "        map2 = laterals[2] + nn.functional.interpolate(map3, scale_factor=2, mode=\"nearest\")\n",
    "        map1 = laterals[3] + nn.functional.interpolate(map2, scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "        map1 = self.smooths[0](map1)\n",
    "        map2 = self.smooths[1](torch.cat([map2, self.pooling(map1)], dim=1))\n",
    "        map3 = self.smooths[2](torch.cat([map3, self.pooling(map2)], dim=1))\n",
    "        map4 = self.smooths[3](torch.cat([map4, self.pooling(map3)], dim=1))\n",
    "\n",
    "        return map4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape after FPN forward torch.Size([1, 1024, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "fpn_test = FPN(2048)\n",
    "\n",
    "out = fpn_test([x1, x2, x3, x4][::-1])\n",
    "\n",
    "print('out shape after FPN forward', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, inplanes, bn_momentum=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.bn_momentum = bn_momentum\n",
    "        # backbone output: [b, 2048, _h, _w]\n",
    "        self.inplanes = inplanes\n",
    "        self.deconv_with_bias = False\n",
    "        self.deconv_layers = self._make_deconv_layer(\n",
    "            num_layers=5,\n",
    "            num_filters=[256, 256, 256, 256, 256],\n",
    "            num_kernels=[4, 4, 4, 4, 4],\n",
    "        )\n",
    "\n",
    "    def _make_deconv_layer(self, num_layers, num_filters, num_kernels):\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            kernel = num_kernels[i]\n",
    "            padding = 0 if kernel == 2 else 1\n",
    "            output_padding = 1 if kernel == 3 else 0\n",
    "            planes = num_filters[i]\n",
    "            layers.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_channels=self.inplanes,\n",
    "                    out_channels=planes,\n",
    "                    kernel_size=kernel,\n",
    "                    stride=2,\n",
    "                    padding=padding,\n",
    "                    output_padding=output_padding,\n",
    "                    bias=self.deconv_with_bias))\n",
    "            layers.append(nn.BatchNorm2d(planes, momentum=self.bn_momentum))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            self.inplanes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.deconv_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape after decoder forward torch.Size([1, 256, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "decoder_test = Decoder(inplanes=out.shape[1])\n",
    "\n",
    "out = decoder_test(out)\n",
    "\n",
    "print('out shape after decoder forward', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Heads(nn.Module):\n",
    "    def __init__(self, nclasses=53, in_channels = 256):\n",
    "        super(Heads, self).__init__()\n",
    "\n",
    "        self.nclasses = nclasses\n",
    "\n",
    "        self.heat_maps = nn.Sequential(\n",
    "                                            nn.Conv2d(in_channels, out_channels = 64, kernel_size = 3, stride=2, padding=1, bias=True),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(64, self.nclasses, kernel_size = 1, stride=2, padding=0, bias=True)\n",
    "                                        )\n",
    "        \n",
    "        self.offset_maps = nn.Sequential(\n",
    "                                            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(in_channels, 2, kernel_size=1, stride=2, padding=0),\n",
    "                                        )\n",
    "        \n",
    "        self.size_maps = nn.Sequential(\n",
    "                                            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(in_channels, 2, kernel_size=1, stride=2, padding=0),\n",
    "                                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        heat = self.heat_maps(x)\n",
    "        offset = self.offset_maps(x)\n",
    "        size = self.size_maps(x)\n",
    "\n",
    "        return heat, offset, size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted heatmaps shape: torch.Size([1, 53, 64, 64])\n",
      "predicted offset shape: torch.Size([1, 2, 64, 64])\n",
      "predicted size shape: torch.Size([1, 2, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "heads_test = Heads()\n",
    "\n",
    "heat, offset, size = heads_test(out)\n",
    "\n",
    "print('predicted heatmaps shape:', heat.shape)\n",
    "print('predicted offset shape:', offset.shape)\n",
    "print('predicted size shape:', size.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
