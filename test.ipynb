{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_feature(fmap, index, mask=None, use_transform=False):\n",
    "    if use_transform:\n",
    "        # change a (N, C, H, W) tenor to (N, HxW, C) shape\n",
    "        batch, channel = fmap.shape[:2]\n",
    "        fmap = fmap.view(batch, channel, -1).permute((0, 2, 1)).contiguous()\n",
    "\n",
    "    dim = fmap.size(-1)\n",
    "    index = index.unsqueeze(len(index.shape)).expand(*index.shape, dim)\n",
    "    fmap = fmap.gather(dim=1, index=index)\n",
    "    if mask is not None:\n",
    "        # this part is not called in Res18 dcn COCO\n",
    "        mask = mask.unsqueeze(2).expand_as(fmap)\n",
    "        fmap = fmap[mask]\n",
    "        fmap = fmap.reshape(-1, dim)\n",
    "    return fmap\n",
    "\n",
    "def topKscoresPerBatch(fmaps, K=40):\n",
    "    batch, channels, height, width = fmaps.shape\n",
    "\n",
    "    # first we want the top K per fmaps\n",
    "    flattened_hmaps = fmaps.reshape(batch, channels, -1)\n",
    "    topk_scores_per_cls, topk_indices = torch.topk(flattened_hmaps, K)\n",
    "\n",
    "    # computing x and y in (h, w) space\n",
    "    topk_indices = topk_indices % (height * width)\n",
    "    topk_x = (topk_indices / width).int().float()  \n",
    "    topk_y = (topk_indices % width).int().float()\n",
    "\n",
    "    # now we want the topk all classes merged, for each batch separatly\n",
    "    flattened_cls = topk_scores_per_cls.reshape(batch, -1)\n",
    "    topk_scores, indices = torch.topk(flattened_cls, K)\n",
    "\n",
    "    topk_cls = (indices / K).int() # compute wich cls the topk belong\n",
    "\n",
    "    # updating indices, x and y by matching indices and previous top40 for each hmaps\n",
    "    topk_indices = gather_feature(topk_indices.view(batch, -1, 1), indices).reshape(batch, K)\n",
    "    topk_x = gather_feature(topk_x.reshape(batch, -1, 1), indices).reshape(batch, K)\n",
    "    topk_y = gather_feature(topk_y.reshape(batch, -1, 1), indices).reshape(batch, K)\n",
    "\n",
    "    return topk_scores, topk_indices, topk_cls, topk_y, topk_x\n",
    "# so this function is returning the top 40 activations all classes merged for every batch independantly. they are broke down into:\n",
    "# the top 40 score sorted in descending order\n",
    "# the top 40 indices in the (4, 53, 4096) list\n",
    "# the top 40 score's x and y in the original features maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk indices:\n",
      "tensor([[1683, 1601, 2587,  167, 1570, 1128],\n",
      "        [3333, 3333, 2121, 1009, 1341, 2368],\n",
      "        [2292, 3478, 1897, 3110, 2540, 1980],\n",
      "        [1018, 3235,  897, 2463,  491, 3238]])\n",
      "\n",
      "(x, y) in original heat maps features maps:\n",
      "(26.0, 19.0)\n",
      "(25.0, 1.0)\n",
      "(40.0, 27.0)\n",
      "(2.0, 39.0)\n",
      "(24.0, 34.0)\n",
      "(17.0, 40.0)\n"
     ]
    }
   ],
   "source": [
    "fmap_test = torch.rand(4, 53, 64, 64)\n",
    "\n",
    "topk_score, topk_inds, topk_clses, topk_ys, topk_xs = topKscoresPerBatch(fmap_test, K=40)\n",
    "\n",
    "print(f'topk indices:\\n{topk_inds[:, 0:6]}')\n",
    "\n",
    "\n",
    "print('\\n(x, y) in original heat maps features maps:')\n",
    "for x, y in zip(topk_xs[0, 0:6], topk_ys[0, 0:6]):\n",
    "    print(f'({x}, {y})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 40, 2]) torch.Size([4, 40])\n"
     ]
    }
   ],
   "source": [
    "def gather_feature2(fmap, index, mask=None, use_transform=False):\n",
    "    if use_transform:\n",
    "        # change a (N, C, H, W) tenor to (N, HxW, C) shape\n",
    "        batch, channel = fmap.shape[:2]\n",
    "        fmap = fmap.view(batch, channel, -1).permute((0, 2, 1)).contiguous()\n",
    "    dim = fmap.size(-1)\n",
    "\n",
    "    index = index.unsqueeze(len(index.shape)).expand(*index.shape, dim)\n",
    "    fmap = fmap.gather(dim=1, index=index)\n",
    "    return fmap\n",
    "\n",
    "pred_offset = torch.rand(4, 2, 64, 64)\n",
    "\n",
    "pred_offset_gathered = gather_feature2(pred_offset, topk_inds, use_transform=True)\n",
    "\n",
    "print(pred_offset_gathered.shape, topk_inds.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 40, 2])\n"
     ]
    }
   ],
   "source": [
    "test = torch.rand(4, 40)\n",
    "test = test.unsqueeze(len(test.shape))\n",
    "\n",
    "print(test.expand(4, 40, 2).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "torch.return_types.sort(\n",
      "values=tensor([4, 3, 2, 1]),\n",
      "indices=tensor([3, 2, 1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with size (2, 3)\n",
    "tensor = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "print(tensor)\n",
    "print(torch.sort(tensor, descending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
